{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excited-device",
   "metadata": {},
   "source": [
    "# Example of station forecasts postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-election",
   "metadata": {},
   "source": [
    "In this notebook, using Pythie, we postprocess the 2 metre temperature forecasts at a station. We postprocess it with the 2 metre temperature itself, the maximum 2 metre temperature in the last 6 hours and the soil temperature as predictors.\n",
    "\n",
    "We use the observation data of the [WMO](https://public.wmo.int/en)-compliant [DWD](https://www.dwd.de) meteorological station of [Soltau](https://en.wikipedia.org/wiki/Soltau) from 1997 to 2016.\n",
    "The station is located at the point [52°57'37.5\"N, 9°47'35.0\"E](https://www.google.com/maps/place/52%C2%B057'37.5%22N+9%C2%B047'35.0%22E/@52.9507203,9.7805715,14.5z). The data have been downloaded from the DWD [Climate Data Center](https://cdc.dwd.de/portal/).\n",
    "\n",
    "The postprocessing is done by making a regression at each lead time between the reforecasts at a nearby (5.3 km) grid point [53°00'00.0\"N, 9°45'00.0\"E](https://www.google.com/maps/place/53%C2%B000'00.0%22N+9%C2%B045'00.0%22E/@53.0205719,9.7147325,12.25z). For verification, the result of this regression is then applied on the reforecasts themselves (the training set).\n",
    "\n",
    "The reforecasts at the grid point have been extracted from the reforecasts gridded data available in the gridded reforecasts and reanalysis dataset.\n",
    "\n",
    "**Note:** *In the following example, we drop the initial conditions of the reforecasts because one of the maximum 2 meter temperature is not defined at this lead time ! As a result, we do not postprocess the lead time 0.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-premiere",
   "metadata": {},
   "source": [
    "**Warning:** To perform the computation of this example notebook, you need first to download from [Zenodo](https://zenodo.org/) the gridded observation and reforecast dataset. You also need to install the extra packages. See the [README.md](../README.md) file for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-elder",
   "metadata": {},
   "source": [
    "#### Observation data source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-workplace",
   "metadata": {},
   "source": [
    "Source: [Deutscher Wetterdienst](https://www.dwd.de/), [DWD CDC portal](https://cdc.dwd.de/portal/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-index",
   "metadata": {},
   "source": [
    "#### Reforecast data source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-extraction",
   "metadata": {},
   "source": [
    "Source: www.ecmwf.int\n",
    "\n",
    "Creative Commons Attribution 4.0 International (CC BY 4.0)\n",
    "Copyright © 2021 European Centre for Medium-Range Weather Forecasts (ECMWF).\n",
    "See the attached ECMWF_LICENSE.txt file included with the data for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-career",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-twenty",
   "metadata": {},
   "source": [
    "Setting the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.extend([os.path.abspath('../')])\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-montreal",
   "metadata": {},
   "source": [
    "Importing external modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','sans-serif':['Times'],'size':16})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-dimension",
   "metadata": {},
   "source": [
    "Importing internal modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data import Data\n",
    "import postprocessors.MBM as MBM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-samuel",
   "metadata": {},
   "source": [
    "Setting some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date of the forecast\n",
    "date = \"01-02\"\n",
    "# Year to correct\n",
    "year = 2017\n",
    "# Number of reforecasts\n",
    "years_back = 20\n",
    "# Parameter of the observations (to be postprocessed)\n",
    "param = '2t'\n",
    "# Parameters of the predictors\n",
    "params = ['2t', 'mx2t6', 'stl1']\n",
    "# Locaction of the data\n",
    "data_folder = './data/soltau/'\n",
    "# Station considered\n",
    "station = 4745"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-timing",
   "metadata": {},
   "source": [
    "## Loading and creating the Data objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-thomas",
   "metadata": {},
   "source": [
    "**This section shows how to load Data objects from csv files using pandas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-leeds",
   "metadata": {},
   "source": [
    "Loading the reforecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "# First create a list of pandas Dataframes from the csv files\n",
    "reforecasts_temp = list()\n",
    "for y in range(year-years_back, year):\n",
    "    # note : we skip the first row to drop the forecast initial condition\n",
    "    reforecasts_temp.append(pd.read_csv(data_folder + 'reforecasts_2t_' + str(y) + '-' + date + '_' + str(station) + '.csv', index_col=0, parse_dates=True, skiprows=[1]))\n",
    "# Then a Data object from this list, loading it along the observation axis, and each member of the list along the member axis\n",
    "reforecasts_data_2t = Data()\n",
    "reforecasts_data_2t.load_scalars(reforecasts_temp, load_axis=['obs', 'member'], columns='all')\n",
    "reforecasts_data_list = list()\n",
    "reforecasts_data_list.append(reforecasts_data_2t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-assembly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for the maximum temperature over the last 6 hours\n",
    "reforecasts_data_mx2t6 = Data()\n",
    "reforecasts_mx2t6 = list()\n",
    "for y in range(year-years_back, year):\n",
    "    # note : we skip the first row to drop the forecast initial condition\n",
    "    reforecasts_mx2t6.append(pd.read_csv(data_folder + 'reforecasts_mx2t6_' + str(y) + '-' + date + '_' + str(station) + '.csv', index_col=0, parse_dates=True, skiprows=[1]))\n",
    "reforecasts_data_mx2t6.load_scalars(reforecasts_mx2t6, load_axis=['obs', 'member'], columns='all')\n",
    "reforecasts_data_list.append(reforecasts_data_mx2t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for the soil temperature\n",
    "reforecasts_data_stl1 = Data()\n",
    "reforecasts_stl1 = list()\n",
    "for y in range(year-years_back, year):\n",
    "    # note : we skip the first row to drop the forecast initial condition\n",
    "    reforecasts_stl1.append(pd.read_csv(data_folder + 'reforecasts_stl1_' + str(y) + '-' + date + '_' + str(station) + '.csv', index_col=0, parse_dates=True, skiprows=[1]))\n",
    "reforecasts_data_stl1.load_scalars(reforecasts_stl1, load_axis=['obs', 'member'], columns='all')\n",
    "reforecasts_data_list.append(reforecasts_data_stl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the first predictor (the variable itself) for latter\n",
    "reforecast_data_1st_predictor = reforecasts_data_list[0].copy()\n",
    "\n",
    "# Then loading all the predictors into one single Data object\n",
    "reforecasts_data = reforecasts_data_list[0].copy()\n",
    "for reforecast in reforecasts_data_list[1:]:\n",
    "    reforecasts_data.append_predictors(reforecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-viewer",
   "metadata": {},
   "source": [
    "Loading the observations corresponding to the reforecast data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipping the initial condition of the forecast and taking 6-hourly observations to match the reforecasts timestep\n",
    "skiprows = lambda x: x==1 or (x != 0 and (x-1) % 6 != 0)\n",
    "# Temperature\n",
    "# First create a list of pandas Dataframes from the csv files\n",
    "past_obs_temp = list()\n",
    "for y in range(year-years_back, year):\n",
    "    past_obs_temp.append(pd.read_csv(data_folder + 'past_observations_2t_' + str(y) + '-' + date + '_' + str(station) + '.csv', index_col=0, parse_dates=True, skiprows=skiprows))\n",
    "# Then a Data object from this list, loading it along the observation axis, and each member of the list along the member axis\n",
    "past_obs_data = Data()\n",
    "for obs in past_obs_temp:\n",
    "    past_obs_data.load_scalars(obs, load_axis='obs', columns='2t', concat_axis='obs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-champagne",
   "metadata": {},
   "source": [
    "## Training the PostProcessors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-milan",
   "metadata": {},
   "source": [
    "In this section, we train the various different postprocessors of the Member-By-Member MBM module with the data previously loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold the trained PostProcessors\n",
    "postprocessors = list()\n",
    "proc_labels = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-nickel",
   "metadata": {},
   "source": [
    "### Simple bias correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ebc = MBM.BiasCorrection()\n",
    "ebc.train(past_obs_data, reforecasts_data)\n",
    "postprocessors.append(ebc)\n",
    "proc_labels.append('Bias correction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-atmosphere",
   "metadata": {},
   "source": [
    "### Ensemble Mean correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "emc = MBM.EnsembleMeanCorrection()\n",
    "emc.train(past_obs_data, reforecasts_data)\n",
    "postprocessors.append(emc)\n",
    "proc_labels.append('Ensemble Mean correction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-motel",
   "metadata": {},
   "source": [
    "### Ensemble Spread Scaling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "essc = MBM.EnsembleSpreadScalingCorrection()\n",
    "essc.train(past_obs_data, reforecasts_data)\n",
    "postprocessors.append(essc)\n",
    "proc_labels.append('Ensemble Spread Scaling correction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-doctrine",
   "metadata": {},
   "source": [
    "### Ensemble Spread Scaling correction with Absolute norm CRPS minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "essacc = MBM.EnsembleSpreadScalingAbsCRPSCorrection()\n",
    "essacc.train(past_obs_data, reforecasts_data, ntrial=10)\n",
    "postprocessors.append(essacc)\n",
    "proc_labels.append('Ensemble Spread Scaling Abs. CRPS min. correction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-equipment",
   "metadata": {},
   "source": [
    "### Ensemble Spread Scaling correction + Climatology nudging with Absolute norm CRPS minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "eacc = MBM.EnsembleAbsCRPSCorrection()\n",
    "eacc.train(past_obs_data, reforecasts_data, ntrial=10)\n",
    "postprocessors.append(eacc)\n",
    "proc_labels.append('Ensemble Spread Scaling + Clim. Nudging Abs. CRPS min. correction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-mexican",
   "metadata": {},
   "source": [
    "### Ensemble Spread Scaling correction + Climatology nudging with Ngr CRPS minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "encc = MBM.EnsembleNgrCRPSCorrection()\n",
    "encc.train(past_obs_data, reforecasts_data, ntrial=10)\n",
    "postprocessors.append(encc)\n",
    "proc_labels.append('Ensemble Spread Scaling + Clim. Nudging Ngr CRPS min. correction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-graduation",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-robertson",
   "metadata": {},
   "source": [
    "Here we are going to postprocess the reforecasts themselves to see how well they perform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the experiment names\n",
    "exp_results = list()\n",
    "exp_results.append(reforecast_data_1st_predictor)\n",
    "exp_labels = list()\n",
    "exp_labels.append('Raw forecasts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = np.array(range(reforecast_data_1st_predictor.number_of_time_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-programming",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, postprocessor in zip(proc_labels, postprocessors):\n",
    "    exp_results.append(postprocessor(reforecasts_data))\n",
    "    exp_labels.append(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-dividend",
   "metadata": {},
   "source": [
    "### Computing scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-buffer",
   "metadata": {},
   "source": [
    "Computing the bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the CRPS Data object\n",
    "bias = list()\n",
    "for label, result in zip(exp_labels, exp_results):\n",
    "    bias.append(result.bias(past_obs_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-queue",
   "metadata": {},
   "source": [
    "Computing the ensemble mean RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the CRPS Data object\n",
    "rmse = list()\n",
    "for label, result in zip(exp_labels, exp_results):\n",
    "    rmse.append(result.ensemble_mean_RMSE(past_obs_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-thousand",
   "metadata": {},
   "source": [
    "Computing the CRPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the CRPS Data object\n",
    "crps = list()\n",
    "for label, result in zip(exp_labels, exp_results):\n",
    "    crps.append(result.CRPS(past_obs_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-instrument",
   "metadata": {},
   "source": [
    "### Plotting the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.gca()\n",
    "\n",
    "first = True\n",
    "for c, lab in zip(crps, exp_labels):\n",
    "    if first:\n",
    "        c.plot(ax=ax, global_label=lab, timestamps=timestamps, lw=3., ls=\"--\")\n",
    "        first = False\n",
    "    else:\n",
    "        c.plot(ax=ax, global_label=lab, timestamps=timestamps)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('CRPS Score at station '+str(station))\n",
    "ax.set_ylabel('CRPS [C°]')\n",
    "ax.set_xlabel('time x 6hrs');\n",
    "ax.set_ylim(0., 3.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.gca()\n",
    "\n",
    "first = True\n",
    "for c, lab in zip(rmse, exp_labels):\n",
    "    if first:\n",
    "        c.plot(ax=ax, global_label=lab, timestamps=timestamps, lw=3., ls=\"--\")\n",
    "        first = False\n",
    "    else:\n",
    "        c.plot(ax=ax, global_label=lab, timestamps=timestamps)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('RMSE Score at station '+str(station))\n",
    "ax.set_ylabel('RMSE [C°]')\n",
    "ax.set_xlabel('time x 6hrs');\n",
    "ax.set_ylim(0., 5.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.gca()\n",
    "\n",
    "first = True\n",
    "for c, lab in zip(bias, exp_labels):\n",
    "    if first:\n",
    "        c.plot(ax=ax, global_label=lab, timestamps=timestamps, lw=3., ls=\"--\")\n",
    "        first = False\n",
    "    else:\n",
    "        c.plot(ax=ax, global_label=lab, timestamps=timestamps)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('Bias at station '+str(station))\n",
    "ax.set_ylabel('Bias [C°]')\n",
    "ax.set_xlabel('time x 6hrs');\n",
    "ax.set_ylim(-3., 1.);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-denmark",
   "metadata": {},
   "source": [
    "### Example of a postprocessing parameters plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.gca()\n",
    "postprocessors[-2].plot_parameters(ax=ax);\n",
    "ax.set_ylim(-8.,8.)\n",
    "ax.set_xlabel('Timestep [hours]')\n",
    "ax.set_title('Postprocessing parameters\\n('+exp_labels[-2]+')');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-elements",
   "metadata": {},
   "source": [
    "### Example of a reforecast plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Data(reforecast_data_1st_predictor[0,-2][np.newaxis, np.newaxis,...], timestamps=[reforecast_data_1st_predictor.timestamps[0,-2]])\n",
    "b = Data(exp_results[-1][0,-2][np.newaxis, np.newaxis,...], timestamps=[reforecast_data_1st_predictor.timestamps[0,-2]])\n",
    "bb = Data(exp_results[-2][0,-2][np.newaxis, np.newaxis,...], timestamps=[reforecast_data_1st_predictor.timestamps[0,-2]])\n",
    "c = Data(past_obs_data[0,-2][np.newaxis, np.newaxis,...], timestamps=[past_obs_data.timestamps[0,-2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.gca()\n",
    "\n",
    "a.plot(color='tab:blue', ax=ax, global_label='Raw ensemble reforecast')\n",
    "b.plot(color='tab:orange', ax=ax, global_label='Ngr Corrected ensemble reforecast')\n",
    "c.plot(color='g', ax=ax, label='Station Observation', lw=4.)\n",
    "ax.set_title('Reforecasts at station '+str(station))\n",
    "ax.set_ylabel('Date')\n",
    "ax.set_xlabel('2m Temperature [C°]')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.gca()\n",
    "\n",
    "a.plot(color='tab:blue', ax=ax, global_label='Raw ensemble reforecast')\n",
    "bb.plot(color='tab:orange', ax=ax, global_label='Abs Corrected ensemble reforecast')\n",
    "c.plot(color='g', ax=ax, label='Station Observation', lw=4.)\n",
    "ax.set_title('Reforecasts at station '+str(station))\n",
    "ax.set_ylabel('Date')\n",
    "ax.set_xlabel('2m Temperature [C°]')\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
